import pandas as pd
import numpy as np
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.llms import Ollama
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_core.documents import Document
from tqdm import tqdm

# === Step 1: Load CSV ===
loader = CSVLoader(
    file_path=r"C:\Users\assis\Downloads\Pubmed_cleaned_csv.csv",
    encoding="utf-8",
    source_column="Abstract",
    metadata_columns=["PMID", "Title"],
    csv_args={"delimiter": ",", "quotechar": '"', "skipinitialspace": True}
)
docs = loader.load()

# === Step 2: Initialize Embedding Model ===
embedding_model = OllamaEmbeddings(model="mxbai-embed-large")

# === Step 3: Build FAISS Vector Store ===
db = FAISS.from_documents(docs, embedding_model)

# === Step 4: Define Evaluation Prompt and Chain ===
eval_prompt = PromptTemplate.from_template(
    """
You are a pharmacovigilance expert. Evaluate the abstract below and answer:
"Does this abstract provide information relevant to the 'Characterisation of Benefit Data' section of a PSUR based on the criteria listed?"

Return only "Yes" or "No".

Criteria: dose-response, duration, comparative efficacy, strengths/limitations, effect size, rigor, relevance.

Abstract:
{abstract}
"""
)
llm = Ollama(model="llama3")
eval_chain = LLMChain(llm=llm, prompt=eval_prompt)

# === Step 5: Evaluate Abstracts and Add Scores ===
results = []
for doc in tqdm(docs, desc="Evaluating abstracts..."):
    abstract = doc.page_content.strip()
    meta = doc.metadata
    if not abstract:
        continue
    resp = eval_chain.run({"abstract": abstract}).strip()
    if "yes" in resp.lower():
        decision, score = "Yes", 1
    elif "no" in resp.lower():
        decision, score = "No", 0
    else:
        decision, score = "Unclear", np.nan
    results.append({
        "PMID": meta.get("PMID", ""),
        "Title": meta.get("Title", ""),
        "Abstract": abstract,
        "LLM_Evaluation": decision,
        "Score": score
    })

# === Step 6: Create DataFrame and Save ===
df_result = pd.DataFrame(results)
df_result.to_csv("psur_abstract_evaluation_with_scores.csv", index=False)

# === Step 7: Define Drug-Detection Prompt and Chain ===
drug_prompt = PromptTemplate.from_template(
    """
You are a pharmacovigilance expert. Does the following abstract discuss *only* the drug sacubitril/valsartan? Return "Yes" or "No".

Abstract:
{abstract}
"""
)
drug_chain = LLMChain(llm=llm, prompt=drug_prompt)

# === Step 8: Filter Abstracts via LLM Response ===
filtered = []
for doc in tqdm(docs, desc="Filtering for sacubitril/valsartan abstracts..."):
    abstract = doc.page_content.strip()
    if not abstract:
        continue
    resp = drug_chain.run({"abstract": abstract}).strip()
    if "yes" in resp.lower():
        filtered.append({
            "PMID": doc.metadata.get("PMID", ""),
            "Title": doc.metadata.get("Title", ""),
            "Abstract": abstract,
            "LLM_Evaluation": df_result.loc[df_result["PMID"] == doc.metadata.get("PMID"), "LLM_Evaluation"].values[0],
            "Score": df_result.loc[df_result["PMID"] == doc.metadata.get("PMID"), "Score"].values[0]
        })
# === Step 9: Create Filtered DataFrame and Save ===
df_filtered = pd.DataFrame(filtered)
df_filtered.to_csv("filtered_abstracts_sacubitril_valsartan_llm.csv", index=False)

# === Step 10: Display to User ===
from ace_tools import display_dataframe_to_user

display_dataframe_to_user("PSUR Abstracts with Scores", df_result)
display_dataframe_to_user("Sacubitril/Valsartan Abstracts", df_filtered)
